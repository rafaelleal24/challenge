# Challenge API
API RESTful desenvolvida em Go para gerenciamento de pedidos com mensageria ass√≠ncrona e observabilidade.

## üìã Stack T√©cnica

### Banco de Dados
- **MongoDB**: Utilizado como banco de dados principal, conforme requisito obrigat√≥rio do projeto. 

‚ö†Ô∏è **Importante**: As transa√ß√µes do MongoDB s√≥ funcionam com **Replica Set** habilitado. Inst√¢ncias standalone n√£o possuem suporte a transa√ß√µes e causar√£o erros na aplica√ß√£o. O `docker-compose.yml` fornecido j√° configura o MongoDB em modo Replica Set.

### Mensageria
- **RabbitMQ**: Sistema de mensageria para processamento ass√≠ncrono de eventos, conforme requisito obrigat√≥rio do projeto.

### Cache, Idempot√™ncia e Rate Limiting
- **Redis**: Utilizado para tr√™s finalidades:
  - Armazenamento de cache para otimiza√ß√£o de performance
  - Gerenciamento de chaves de idempot√™ncia para evitar processamento duplicado de requisi√ß√µes
  - Rate limiting por rota via Lua script at√¥mico (`INCR` + `EXPIRE`)

### Observabilidade

- **OpenTelemetry Collector**: Coletor de telemetria que centraliza o envio de logs. A principal vantagem √© a flexibilidade: podemos alterar o destino dos logs (Loki, Elasticsearch, OpenSearch, etc.) apenas modificando o arquivo de configura√ß√£o, sem necessidade de mudan√ßas no c√≥digo.

- **Loki**: Sistema de agrega√ß√£o de logs escolhido por sua simplicidade de configura√ß√£o e baixo overhead operacional.

- **Grafana**: Interface para visualiza√ß√£o de logs do Loki. J√° vem pr√©-configurado com o datasource correto. Pode ser expandido para visualiza√ß√£o de m√©tricas no futuro.

## üöÄ Como Rodar o Projeto

O projeto possui duas configura√ß√µes Docker Compose:

### 1. Ambiente Simples (docker-compose.yml)

Configura√ß√£o b√°sica com logs direcionados para stdout:

```bash
docker compose up -d
```

Nesta configura√ß√£o:
- Logs s√£o enviados para stdout/stderr
- `IS_PRODUCTION=false`
- Servi√ßos: API, MongoDB, Redis, RabbitMQ

### 2. Ambiente com Observabilidade (docker-compose-full.yml)

Configura√ß√£o completa com stack de observabilidade:

```bash
docker compose -f docker-compose-full.yml up -d
```

Nesta configura√ß√£o:
- Logs s√£o enviados para Loki via OpenTelemetry Collector
- `IS_PRODUCTION=true`
- Servi√ßos: API, MongoDB, Redis, RabbitMQ, OpenTelemetry Collector, Loki, Grafana
- Acesse o Grafana em `http://localhost:3000` (usu√°rio: `admin`, senha: `admin`)

### Portas Expostas

| Servi√ßo | Porta | Descri√ß√£o |
|---------|-------|-----------|
| API | 8080 | Endpoint HTTP da aplica√ß√£o |
| MongoDB | 27017 | Banco de dados |
| Redis | 6379 | Cache e idempot√™ncia |
| RabbitMQ | 5672 | AMQP |
| RabbitMQ Management | 15672 | Interface de gerenciamento |
| Grafana | 3000 | Dashboard de logs |
| Loki | 3100 | Agregador de logs |
| OTEL Collector | 4317 | gRPC receiver |

## üîç Como Testar a API

### 1. Criar um Customer

```bash
curl -X POST http://localhost:8080/api/v1/customers \
  -H "Content-Type: application/json"
```

**Resposta**:
```json
{
  "id": "698bb701ec717b7a0d5ac8b0"
}
```

Anote o `id` retornado, pois ser√° usado nos pr√≥ximos passos.

### 2. Criar um Produto

```bash
curl -X POST http://localhost:8080/api/v1/products \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test Product",
    "description": "This is a test product",
    "price": 2999,
    "stock": 100
  }'
```

**Observa√ß√µes**:
- O pre√ßo √© em centavos (2999 = $29.99)
- Anote o `id` do produto retornado

**Resposta**:
```json
{
  "id": "698bb701ec717b7a0d5ac8b1",
  "name": "Test Product",
  "description": "This is a test product",
  "price": 2999,
  "stock": 100
}
```

### 3. Criar um Pedido (com Idempot√™ncia)

```bash
curl -X POST http://localhost:8080/api/v1/orders \
  -H "Content-Type: application/json" \
  -H "Idempotency-Key: test-key-123" \
  -d '{
    "customer_id": "698bb701ec717b7a0d5ac8b0",
    "items": [
      {
        "product_id": "698bb701ec717b7a0d5ac8b1",
        "quantity": 1
      }
    ]
  }'
```

**Testando Idempot√™ncia**: Execute o mesmo comando novamente com a mesma `Idempotency-Key`. Voc√™ receber√° a mesma resposta com o mesmo `order_id`, confirmando que o pedido n√£o foi processado duas vezes.

**Resposta**:
```json
{
  "id": "698bb701ec717b7a0d5ac8b2",
  "customer_id": "698bb701ec717b7a0d5ac8b0",
  "items": [...],
  "status": "created",
  "total_amount": 2999
}
```

### 4. Atualizar Status do Pedido

```bash
curl -X PATCH http://localhost:8080/api/v1/orders/698bb701ec717b7a0d5ac8b2/status \
  -H "Content-Type: application/json" \
  -d '{
    "status": "processing"
  }'
```

**Resposta**:
```json
{
  "id": "698bb701ec717b7a0d5ac8b2",
  "status": "processing"
}
```

### üìö Documenta√ß√£o OpenAPI/Swagger

A especifica√ß√£o da API est√° dispon√≠vel nos arquivos `docs/swagger.yaml` e `docs/swagger.json`, gerados automaticamente via `swaggo` a partir das anota√ß√µes nos controllers.

> **Nota**: O Swagger UI n√£o √© servido pela aplica√ß√£o em runtime. Para visualizar a documenta√ß√£o, importe o arquivo em ferramentas como [Swagger Editor](https://editor.swagger.io/), Postman ou Insomnia.

## üß™ Testes Unit√°rios

### 1. Instalar Ferramenta de Cobertura

```bash
go install github.com/vladopajic/go-test-coverage/v2@latest
```

### 2. Executar Testes

**Importante (Windows)**: Certifique-se de que o Docker Desktop est√° rodando, pois alguns testes utilizam Testcontainers para testar os adapters (camadas externas).

```bash
go test ./... -coverprofile=coverage.out
```

### 3. Verificar Cobertura

```bash
go-test-coverage --config=./.testcoverage.yml
```

**Cobertura Atual**: 61.7%

### Paths Exclu√≠dos da Cobertura

Os seguintes paths foram exclu√≠dos da an√°lise de cobertura por n√£o necessitarem de testes unit√°rios:

```yaml
exclude:
  paths:
    - ^cmd/              # Entrypoint da aplica√ß√£o
    - /port/             # Interfaces/portas
    - /config/           # Arquivos de configura√ß√£o
    - ^docs/             # Documenta√ß√£o
    - /serviceerrors/    # Defini√ß√µes de erros
    - /logger/           # Implementa√ß√£o de logger
    - /mock/             # Mocks para testes
    - /document/         # Modelos de dados
    - /dto/              # Data Transfer Objects
    - router.go          # Configura√ß√£o de rotas
```

**Justificativa**: Esses arquivos n√£o cont√™m l√≥gica de neg√≥cio relevante (mocks, DTOs, configura√ß√µes, logger, documenta√ß√£o, entrypoint inicial), sendo desnecess√°rio test√°-los unitariamente.

## üèóÔ∏è Decis√µes T√©cnicas

### 1. Outbox Pattern

Implementamos o **Outbox Pattern** para envio de eventos ao RabbitMQ:

- Eventos s√£o salvos em uma tabela outbox no MongoDB dentro da mesma transa√ß√£o da opera√ß√£o principal
- Um worker separado processa e envia os eventos
- **Garantia**: At-least-once delivery
- **Importante**: Consumidores devem implementar l√≥gica de deduplica√ß√£o ou serem idempotentes, pois eventos podem ser entregues mais de uma vez

### 2. Idempot√™ncia de Requisi√ß√µes

Implementamos chaves de idempot√™ncia seguindo o modelo do Stripe:

- **Evita processamento duplicado**: Se o usu√°rio sofrer problemas de rede e reenviar a requisi√ß√£o, ela n√£o ser√° processada novamente
- **Valida√ß√£o de integridade**: Fazemos hash do body da requisi√ß√£o. Se o body mudar com a mesma chave de idempot√™ncia, a segunda requisi√ß√£o falha
- **Espera ativa**: Se uma requisi√ß√£o ainda est√° sendo processada e chega outra com a mesma chave, a segunda aguarda a conclus√£o da primeira e retorna o mesmo resultado
- **Armazenamento**: Redis √© usado para gerenciar as chaves de idempot√™ncia

### 3. Transa√ß√µes do MongoDB

Utilizamos transa√ß√µes ACID do MongoDB para garantir consist√™ncia:

- **Atomicidade**: Decrementamos o estoque e criamos a ordem na mesma transa√ß√£o
- **Preven√ß√£o de data races**: Opera√ß√µes concorrentes s√£o isoladas
- **Rollback autom√°tico**: Se qualquer opera√ß√£o falhar, toda a transa√ß√£o √© revertida
- **FindOneAndUpdate at√¥mico**: Usamos esta opera√ß√£o para decrementar o estoque e validar disponibilidade atomicamente, evitando race conditions

### 4. Estrat√©gia de Testes

- **Testcontainers**: Testamos todas as camadas, incluindo adapters (camadas externas), usando containers reais do MongoDB, Redis e RabbitMQ
- **Testes de Arquitetura**: Validamos que n√£o h√° viola√ß√µes arquiteturais no c√≥digo (ex: service importando adapter diretamente)
- **Testes de Integra√ß√£o E2E**: Teste completo de ponta a ponta simulando fluxo real
- **Cobertura significativa**: 61.7% excluindo arquivos que n√£o requerem testes

### 5. Logging Estruturado

- Todas as requisi√ß√µes HTTP s√£o logadas com:
  - Status code
  - Dura√ß√£o da requisi√ß√£o
  - Path e m√©todo
  - Informa√ß√µes de erro (quando aplic√°vel)
- **Possibilidades futuras**: Dashboards no Grafana com gr√°ficos de lat√™ncia m√©dia, taxa de erro, throughput, etc.

## ‚öôÔ∏è CI (GitHub Actions)

Pipeline de integra√ß√£o cont√≠nua executado em todo push e pull request, com **6 jobs em paralelo**:

| Job | O que faz |
|-----|-----------|
| **Tests & Coverage** | Executa todos os testes com race detector (`-race`), gera relat√≥rio de cobertura e falha se estiver abaixo de 60% |
| **Format Check** | Valida formata√ß√£o (`gofmt -s`) e organiza√ß√£o de imports (`goimports`) |
| **Go Vet** | An√°lise est√°tica nativa do Go para detectar erros comuns |
| **Static Analysis** | `staticcheck` para detectar bugs, c√≥digo morto e padr√µes incorretos |
| **Golangci-lint** | Linting abrangente com m√∫ltiplos linters configurados em `.golangci.yml` |
| **Security Scan** | `gosec` para detectar vulnerabilidades de seguran√ßa no c√≥digo |

O pipeline de **CD** √© acionado automaticamente ap√≥s o CI passar na branch `main`. Atualmente realiza apenas o **build da imagem Docker** (multi-stage com cache via GitHub Actions), pois n√£o h√° infraestrutura de destino configurada. Em um cen√°rio real, bastaria adicionar o step de push para um registry (ECR, GHCR, etc.) e deploy (Kubernetes, ECS, etc.).

## üìê Diagramas de Arquitetura

### 1. Arquitetura Hexagonal (Microsservi√ßo)

![Diagrama da Arquitetura Hexagonal](./images/diagrama_arquitetura.jpg)

O servi√ßo segue Arquitetura Hexagonal com separa√ß√£o clara entre Core (domain, services, ports) e Adapters (HTTP/Gin, MongoDB, Redis, RabbitMQ). Requests HTTP entram pelos controllers (inbound adapter), passam pelos services no core que orquestram a l√≥gica de neg√≥cio usando interfaces (ports), e os adapters outbound implementam a persist√™ncia, cache e mensageria. Eventos de atualiza√ß√£o de status s√£o salvos via Outbox Pattern na mesma transa√ß√£o do MongoDB e publicados assincronamente no RabbitMQ para servi√ßos consumidores.

### 2. Estrat√©gia de Escalabilidade

![Diagrama de Escalabilidade](./images/diamagra_escalabilidade.jpg)

O fluxo de produ√ß√£o segue: **Client ‚Üí Cloudflare ‚Üí Load Balancer ‚Üí API Gateway ‚Üí N r√©plicas do Order Service**.

Cada r√©plica √© stateless e se conecta a tr√™s clusters compartilhados:

- **MongoDB (Sharding + Replica Set)**: Sharding distribui os dados horizontalmente por shard key (ex: `customer_id`), permitindo crescimento linear de throughput conforme o volume de pedidos aumenta. Cada shard opera com Replica Set para alta disponibilidade e failover autom√°tico. Transa√ß√µes ACID s√£o suportadas inclusive em opera√ß√µes cross-shard.

- **Redis Cluster**: Cache distribu√≠do com particionamento autom√°tico por hash slots. Garante que idempot√™ncia, rate limiting e cache de pedidos funcionem de forma consistente independente de qual r√©plica da API recebe a requisi√ß√£o.

- **RabbitMQ Cluster**: Cluster com quorum queues para durabilidade. Eventos publicados via Outbox Pattern s√£o consumidos por servi√ßos externos (notifica√ß√£o, analytics, shipping) de forma desacoplada.

**Cloudflare** atua como primeira camada de prote√ß√£o (DDoS, WAF, CDN para assets est√°ticos). O **API Gateway** centraliza autentica√ß√£o, rate limiting global e roteamento, enquanto o **Load Balancer** distribui tr√°fego entre r√©plicas via round-robin ou least-connections. Essa arquitetura permite escalar cada componente de forma independente conforme o gargalo identificado.

